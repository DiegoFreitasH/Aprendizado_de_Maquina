{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lista 2 - Regressão logística, métodos estatísticos, KNN e árvores de decisão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def z_score_norm(data):\n",
    "    mean = data.mean(axis=0)\n",
    "    std = data.std(axis=0)\n",
    "    norm = lambda x: (x - mean) / std\n",
    "    inv_norm = lambda norm_x: norm_x * std + mean\n",
    "    return norm(data), norm, inv_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error functions\n",
    "def MSE(Y, Y_hat):\n",
    "    return np.mean((Y - Y_hat)**2)\n",
    "\n",
    "def RMSE(Y, Y_hat):\n",
    "    return np.sqrt(MSE(Y, Y_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.genfromtxt('./breastcancer.csv', delimiter=',')\n",
    "X = dataset[:, :-1]\n",
    "Y = dataset[:, [-1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_evaluation_scores(y, y_predict):\n",
    "    # Make sure both have the same format\n",
    "    y_predict = y_predict.reshape(-1, 1)\n",
    "    y = y.reshape(-1, 1)\n",
    "    \n",
    "    # True Positves\n",
    "    true_positives = np.nonzero((y == 1) & (y_predict == 1))[0]\n",
    "    n_true_positives = len(true_positives)\n",
    "\n",
    "    # False positives\n",
    "    false_positives = np.nonzero((y == 0) & (y_predict == 1))[0]\n",
    "    n_false_positives = len(false_positives) \n",
    "\n",
    "    # False Negatives\n",
    "    false_negatives = np.nonzero((y == 1) & (y_predict==0))[0]\n",
    "    n_false_negatives = len(false_negatives)\n",
    "\n",
    "    # Accurracy\n",
    "    accurracy = np.sum(y == y_predict) / len(y_predict)\n",
    "    \n",
    "    # Recall\n",
    "    recall = n_true_positives / (n_true_positives + n_false_negatives)\n",
    "\n",
    "    # Precision\n",
    "    precision = n_true_positives / (n_true_positives + n_false_positives)\n",
    "\n",
    "    # F1 Score\n",
    "    f1_score = 2 * (recall * precision) / (recall + precision)\n",
    "    \n",
    "    return accurracy, recall, precision, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kfold Validation and Score calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold_validation(model, x, y, verbose=False, n_folds=10, normalize_data=True):\n",
    "    kfold = KFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "    scores_label = ['Accurracy', 'Recall', 'Precision', 'F1-Score']\n",
    "    results = []\n",
    "    \n",
    "    for i, (train_index, test_index) in enumerate(kfold.split(x)):\n",
    "        # get data\n",
    "        fold_x_train, fold_x_test = x[train_index], x[test_index]\n",
    "        fold_y_train, fold_y_test = y[train_index], y[test_index]\n",
    "\n",
    "        # norm\n",
    "        if(normalize_data):\n",
    "            fold_x_train, norm_x, _ = z_score_norm(fold_x_train)\n",
    "            fold_x_test = norm_x(fold_x_test)\n",
    "\n",
    "\n",
    "        # Train\n",
    "        model.fit(fold_x_train, fold_y_train)\n",
    "        \n",
    "        # Predict\n",
    "        fold_y_predict = model.predict(fold_x_test)\n",
    "        \n",
    "        # Evaluate the model\n",
    "        acc, recall, precision, f1_score = model_evaluation_scores(fold_y_test, fold_y_predict)\n",
    "        if(verbose):\n",
    "            print(f'Fold {i+1}')\n",
    "            print(f'Accurracy: {acc}')\n",
    "            print(f'Recall: {recall}')\n",
    "            print(f'Precision: {precision}')\n",
    "            print(f'F1-Score: {f1_score}\\n')\n",
    "\n",
    "\n",
    "        # Store Scores of Fold\n",
    "        results.append([acc, recall, precision, f1_score])\n",
    "    \n",
    "    results = np.array(results)\n",
    "    scores_mean, scores_std = results.mean(axis=0), results.std(axis=0)\n",
    "    for i in range(len(scores_label)):\n",
    "        print(f'{scores_label[i]}')\n",
    "        print(f'Mean: {scores_mean[i] * 100:.2f}%')\n",
    "        print(f'Std: {scores_std[i] * 100:.2f}%')\n",
    "        print()\n",
    "    return scores_mean, scores_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regressão Logistica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sig(x):\n",
    "    return 1/(1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression():\n",
    "    def __init__(self, alpha=.1, n_epochs=1000, add_bias=True):\n",
    "        self.alpha = alpha\n",
    "        self.n_epochs = n_epochs\n",
    "        self.add_bias=add_bias\n",
    "    \n",
    "    def fit(self, X, Y):\n",
    "        \n",
    "        if(self.add_bias):\n",
    "            self.x = np.c_[np.ones(len(X)), X]\n",
    "        else:\n",
    "            self.x = X\n",
    "        \n",
    "        self.y = Y\n",
    "        self.learning_curve = []\n",
    "        n = len(Y)\n",
    "        \n",
    "        # GD algo\n",
    "        self.w = np.zeros((self.x.shape[1], 1))\n",
    "        for i in range(self.n_epochs):\n",
    "            y_hat = sig(self.x @ self.w)\n",
    "\n",
    "            # Calculate error\n",
    "            e = self.y - y_hat\n",
    "\n",
    "            gradient = (self.x.T @ e)/n\n",
    "\n",
    "            # Update w\n",
    "            self.w += self.alpha * gradient\n",
    "\n",
    "            # Calculate Error\n",
    "            error = MSE(self.y, y_hat)\n",
    "            self.learning_curve.append(error)\n",
    "\n",
    "    def predict(self, X):\n",
    "        x = X\n",
    "        if(self.add_bias):\n",
    "            x = np.c_[np.ones(len(X)), X]\n",
    "        return np.round(sig(x @ self.w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo: Regressão Logistica\n",
      "\n",
      "Hyperparametros\n",
      "  > Passo de Apredizagem: 0.1\n",
      "  > Quantidade de Iterações: 1000\n",
      "\n",
      "\n",
      "Scores\n",
      "\n",
      "Accurracy\n",
      "Mean: 97.89%\n",
      "Std: 1.89%\n",
      "\n",
      "Recall\n",
      "Mean: 98.84%\n",
      "Std: 1.43%\n",
      "\n",
      "Precision\n",
      "Mean: 97.69%\n",
      "Std: 2.92%\n",
      "\n",
      "F1-Score\n",
      "Mean: 98.24%\n",
      "Std: 1.67%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "alpha = .1\n",
    "n_epochs = 1000\n",
    "model = LogisticRegression(alpha, n_epochs)\n",
    "print(f'Modelo: Regressão Logistica\\n')\n",
    "print(f'Hyperparametros')\n",
    "print(f'  > Passo de Apredizagem: {alpha}')\n",
    "print(f'  > Quantidade de Iterações: {n_epochs}')\n",
    "print()\n",
    "print()\n",
    "print('Scores\\n')\n",
    "kfold_validation(model, X, Y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise do discriminante Gaussiano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianDiscriminant():\n",
    "    def __init__(self, n_classes=2):\n",
    "        self.n_classes = 2\n",
    "        self.prob_c = [1/self.n_classes for _ in range(self.n_classes)]\n",
    "    \n",
    "    def _create_prob_function(self, p_ck, det, mean, inv):\n",
    "        return lambda x: (np.log(p_ck) - .5*np.log(det) - .5*(x - mean) @ inv @ (x - mean).T).diagonal()\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        self.estimators = []\n",
    "        for i in range(self.n_classes):\n",
    "            # Get the elements of class k == i\n",
    "            ck_index = np.nonzero(y == i)[0]\n",
    "            ck = x[ck_index]\n",
    "            \n",
    "            mean = ck.mean(axis=0)\n",
    "            var = np.cov(ck, rowvar=False)\n",
    "            inv_var = np.linalg.inv(var)\n",
    "            det = np.linalg.det(var)\n",
    "            prob_fn = self._create_prob_function(self.prob_c[i], det, mean, inv_var)\n",
    "            \n",
    "            # estimators holds functions to calculate the p(C_k | x)\n",
    "            self.estimators.append(prob_fn)\n",
    "    \n",
    "    def _predict_proba(self, x):\n",
    "        return np.array([prob_fn(x) for prob_fn in self.estimators]).T\n",
    "\n",
    "    def predict(self, x):\n",
    "        return np.argmax(self._predict_proba(x), axis=1).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo: Discriminante Gaussiano\n",
      "\n",
      "Scores\n",
      "\n",
      "Accurracy\n",
      "Mean: 95.77%\n",
      "Std: 1.99%\n",
      "\n",
      "Recall\n",
      "Mean: 97.13%\n",
      "Std: 2.66%\n",
      "\n",
      "Precision\n",
      "Mean: 96.26%\n",
      "Std: 3.16%\n",
      "\n",
      "F1-Score\n",
      "Mean: 96.63%\n",
      "Std: 1.49%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = GaussianDiscriminant(n_classes=2)\n",
    "print(f'Modelo: Discriminante Gaussiano\\n')\n",
    "print('Scores\\n')\n",
    "kfold_validation(model, X, Y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Gaussiano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianNaiveBayes():\n",
    "    def __init__(self, n_classes=2):\n",
    "        self.n_classes = 2\n",
    "        self.p_ck = [1/self.n_classes for _ in range(self.n_classes)]\n",
    "        \n",
    "    def _create_prob_fn(self, p_ck, mean, var):\n",
    "        return lambda x: np.log(p_ck) - .5*np.sum(np.log(2*np.pi*var), axis=1) - .5*np.sum(((x-mean)**2)/var, axis=1)\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        self.estimators = []\n",
    "        for i in range(self.n_classes):\n",
    "            ck_index = np.nonzero(y == i)[0]\n",
    "            ck = x[ck_index]\n",
    "\n",
    "            mean = ck.mean(axis=0, keepdims=True)\n",
    "            var = ck.var(axis=0, ddof=1, keepdims=True)\n",
    "            prob_fn = self._create_prob_fn(self.p_ck[i], mean, var)\n",
    "            \n",
    "            # estimators holds functions to calculate the p(C_k | x)\n",
    "            self.estimators.append(prob_fn)\n",
    "    \n",
    "    def _predict_proba(self, x):\n",
    "        return np.array([prob(x) for prob in self.estimators]).T\n",
    "\n",
    "    def predict(self, x):\n",
    "        return np.argmax(self._predict_proba(x), axis=1).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo: Nayve Bayes Gaussiano\n",
      "\n",
      "Scores\n",
      "\n",
      "Accurracy\n",
      "Mean: 93.14%\n",
      "Std: 3.39%\n",
      "\n",
      "Recall\n",
      "Mean: 95.16%\n",
      "Std: 3.96%\n",
      "\n",
      "Precision\n",
      "Mean: 94.13%\n",
      "Std: 2.55%\n",
      "\n",
      "F1-Score\n",
      "Mean: 94.59%\n",
      "Std: 2.46%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = GaussianNaiveBayes(n_classes=2)\n",
    "print('Modelo: Nayve Bayes Gaussiano\\n')\n",
    "print('Scores\\n')\n",
    "kfold_validation(model, X, Y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN():\n",
    "    def __init__(self, n_classes=2, n_neighbors=3):\n",
    "        self.n_classes = n_classes\n",
    "        self.n_neighbors = n_neighbors\n",
    "        \n",
    "    def fit(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.dist_const = (self.x**2).sum(axis=1)\n",
    "    \n",
    "    def predict(self, x):\n",
    "        dist_matrix = -2 * x @ self.x.T + (x**2).sum(axis=1, keepdims=True) + self.dist_const\n",
    "        neighbors_index = np.argpartition(dist_matrix, self.n_neighbors, axis=1)[:, :self.n_neighbors]\n",
    "        neighbors_classes = self.y[neighbors_index]\n",
    "        return neighbors_classes.mean(axis=1).round().reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo: KNN\n",
      "\n",
      "Hyperparametros\n",
      "  > Quantidade de Vizinhos: 3\n",
      "\n",
      "\n",
      "Scores\n",
      "\n",
      "Accurracy\n",
      "Mean: 96.30%\n",
      "Std: 2.16%\n",
      "\n",
      "Recall\n",
      "Mean: 99.17%\n",
      "Std: 1.71%\n",
      "\n",
      "Precision\n",
      "Mean: 95.16%\n",
      "Std: 2.51%\n",
      "\n",
      "F1-Score\n",
      "Mean: 97.10%\n",
      "Std: 1.66%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_classes = 2\n",
    "n_neighbors = 3\n",
    "model = KNN(n_classes, n_neighbors)\n",
    "print(f'Modelo: KNN\\n')\n",
    "print(f'Hyperparametros')\n",
    "print(f'  > Quantidade de Vizinhos: {n_neighbors}')\n",
    "print()\n",
    "print()\n",
    "print('Scores\\n')\n",
    "kfold_validation(model, X, Y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Árvore de decisão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo: Árvore de Decisão\n",
      "\n",
      "Hyperparametros\n",
      "  > Indice de Impureza: gini\n",
      "\n",
      "\n",
      "Scores\n",
      "\n",
      "Accurracy\n",
      "Mean: 93.50%\n",
      "Std: 3.59%\n",
      "\n",
      "Recall\n",
      "Mean: 94.62%\n",
      "Std: 3.92%\n",
      "\n",
      "Precision\n",
      "Mean: 94.97%\n",
      "Std: 2.81%\n",
      "\n",
      "F1-Score\n",
      "Mean: 94.78%\n",
      "Std: 3.12%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "criterion = 'gini'\n",
    "model = DecisionTreeClassifier(criterion=criterion, random_state=42)\n",
    "print('Modelo: Árvore de Decisão\\n')\n",
    "print(f'Hyperparametros')\n",
    "print(f'  > Indice de Impureza: {criterion}')\n",
    "print()\n",
    "print()\n",
    "print('Scores\\n')\n",
    "kfold_validation(model, X, Y);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
